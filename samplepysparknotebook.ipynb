{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2fc90b-24bc-4091-9e42-0ace2e43890d",
   "metadata": {
    "tags": [
     "o9_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_Stores = 'select ([Store].[Store_ID] * [Store].[Type] * [Store].[Size]) on column;'\n",
    "\n",
    "\n",
    "# Initialize the O9DataLake with the input parameters and dataframes\n",
    "# Data can be accessed with O9DataLake.get(<Input Name>)\n",
    "# Overwritten values will not be reflected in the O9DataLake after initialization\n",
    "\n",
    "from o9_common_utils.O9DataLake import O9DataLake, ResourceType, DataSource\n",
    "O9DataLake.register(\"Stores\",DataSource.LS, ResourceType.IBPL, _Stores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bbdb8-57d8-46ba-9cf8-c76b93e86c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "import pandas as pd\n",
    "df = spark.read.format('csv').option('header','true').load(\"/mnt/resource/o9_spark_temp/jhub/5300/aabhaschandra_5300/Sales.csv\")\n",
    "sales = df.toPandas()\n",
    "sales['Date'] = pd.to_datetime(sales['Date'])\n",
    "sales['StoreId'] = sales['StoreId'].astype(int)\n",
    "sales['WeeklySales'] = sales['WeeklySales'].astype(float)\n",
    "sales['Department'] = sales['Department'].astype(int)\n",
    "sales['IsHoliday'] = sales['IsHoliday'].astype(bool)\n",
    "\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8250fd-f3f5-48a7-b910-be3e983bd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f82bb-06a5-4497-8f47-14a9b468a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df = O9DataLake.get(\"Stores\")\n",
    "stores_df = df.withColumnRenamed(\"StoreStoreID\",\"StoreId\")\n",
    "stores = stores_df.toPandas()\n",
    "stores['StoreId']  = stores['StoreId'].astype(int)\n",
    "print(stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e820a-5b88-4f9f-b426-ae18a026fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import pandas as pd\n",
    "csv_path = \"https://o9demostorage.blob.core.windows.net/o9demodata/Features.csv\"\n",
    "features = pd.read_csv(csv_path, encoding='utf8')\n",
    "features.rename(columns={'Fuel_Price' : 'FuelPrice'}, inplace=True)\n",
    "features['Date'] = pd.to_datetime(features['Date'])\n",
    "features['StoreId']  = features['StoreId'].astype(int)\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ed57e-3c50-49b2-b67d-4fa580ddc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df=pd.merge(sales,features, on=['StoreId','Date', 'IsHoliday'], how='left')\n",
    "df=pd.merge(df,stores, on=['StoreId'], how='left')\n",
    "\n",
    "df=df.fillna(0)\n",
    "df['Temperature'] = (df['Temperature']- 32) * 5./9.\n",
    "\n",
    "types_encoded, types = df['StoreType'].factorize()\n",
    "df['Type'] = types_encoded\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407876d1-c0ff-4114-a1bc-37f52d9d2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "print('training_data duplicated:{}'.format(df.duplicated().sum()))\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc31ec-2005-48fb-acf9-4d4d087a3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ef35c-f7d2-479c-9932-76d234dddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "tab_info = pd.DataFrame(df.dtypes).T.rename(index={0:'column Type'}) \n",
    "tab_info = tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
    "tab_info = tab_info.append(pd.DataFrame(df.isnull().sum()/df.shape[0]*100).T.\n",
    "                                       rename(index={0: 'null values (%)'}))\n",
    "tab_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afaed4-091f-46f2-807d-927bb405b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_average_sales_week = df.groupby(by=['Date'], as_index=False)['WeeklySales'].sum()\n",
    "df_average_sales = df_average_sales_week.sort_values('WeeklySales', ascending=False)\n",
    "ts = df_average_sales_week.set_index('Date')\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_average_sales_week.Date, df_average_sales_week.WeeklySales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a672393-df0c-4442-b6f4-781dc65dc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_ar_model(ts, orders):\n",
    "    \n",
    "    X=np.array([ ts.values[(i-orders)].squeeze() if i >= np.max(orders) else np.array(len(orders) * [np.nan]) for i in range(len(ts))])\n",
    "    \n",
    "    mask = ~np.isnan(X[:,:1]).squeeze()\n",
    "    \n",
    "    Y= ts.values\n",
    "    \n",
    "    lin_reg=LinearRegression()\n",
    "    \n",
    "    lin_reg.fit(X[mask],Y[mask])\n",
    "    \n",
    "    print(lin_reg.coef_, lin_reg.intercept_)\n",
    "\n",
    "    print('Score factor: %.2f' % lin_reg.score(X[mask],Y[mask]))\n",
    "    \n",
    "    return lin_reg.coef_, lin_reg.intercept_\n",
    "    \n",
    "def predict_ar_model(ts, orders, coef, intercept):\n",
    "    return np.array([np.sum(np.dot(coef, ts.values[(i-orders)].squeeze())) + intercept  if i >= np.max(orders) else np.nan for i in range(len(ts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a36b4-9638-477f-bbeb-da3edc2cb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import numpy as np\n",
    "orders = np.array([1,6,52])\n",
    "coef, intercept = fit_ar_model(ts,orders)\n",
    "pred = pd.DataFrame(index=ts.index, data=predict_ar_model(ts, orders, coef, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebe172-c112-4f5f-a33e-82d50ab58956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955eb77-e733-4650-beca-18c77e89f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "O9DataLake.put(\"Prediction\",pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[pyplatformhivetest] Tenant Conda Environment",
   "language": "python",
   "name": "genieaz_pyplatformhivetest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
